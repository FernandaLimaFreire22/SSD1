# README ‚Äî Classifica√ß√£o da Condi√ß√£o do Motor

O objetivo deste projeto √© desenvolver um M√≠nimo Produto Vi√°vel (MVP) para um problema de classifica√ß√£o, aplicando t√©cnicas de machine learning em um contexto de manuten√ß√£o preditiva.

A tarefa consiste em prever a condi√ß√£o de motores (0 = ruim, 1 = bom) com base em vari√°veis medidas por sensores, como press√£o do √≥leo, press√£o do combust√≠vel, press√£o do fluido de arrefecimento, temperaturas e rota√ß√µes por minuto (RPM).

Esse tipo de solu√ß√£o pode auxiliar empresas na tomada de decis√µes de manuten√ß√£o, reduzindo falhas inesperadas e otimizando custos operacionais.

Hip√≥tese

As vari√°veis coletadas pelos sensores dos motores cont√™m informa√ß√µes suficientes para prever corretamente se o motor se encontra em boa condi√ß√£o (1) ou em m√° condi√ß√£o (0).

## 1) Configura√ß√£o inicial e imports
As bibliotecas abaixo s√£o necess√°rias para rodar o projeto.

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.dummy import DummyClassifier
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score, roc_curve
)
import joblib
import warnings
warnings.filterwarnings('ignore')

RANDOM_STATE = 42
np.random.seed(RANDOM_STATE)

print('‚úÖ Bibliotecas importadas com sucesso!')
```

## 2) Carregamento e defini√ß√£o do problema
O dataset √© carregado diretamente do reposit√≥rio e a vari√°vel alvo √© `Engine Condition`.

```python
url = 'https://raw.githubusercontent.com/FernandaLimaFreire22/SSD1/main/engine_data2.csv'
df = pd.read_csv(url, sep=';')

print('\nAmostra do Dataset Original:')
print(df.head())
print('\nFormato (linhas, colunas):', df.shape)
print('\nTipos das colunas:\n', df.dtypes)

# Converter colunas que vieram como string com separador errado
cols_to_convert = ['Lub oil pressure', 'Fuel pressure', 'Coolant pressure', 'lub oil temp', 'Coolant temp']
for col in cols_to_convert:
    df[col] = df[col].astype(str).str.replace('.', '', regex=False)
    df[col] = pd.to_numeric(df[col])

print('\nDescri√ß√£o estat√≠stica:')
display(df.describe().T)

print('\nDistribui√ß√£o da vari√°vel alvo (Engine Condition):')
print(df['Engine Condition'].value_counts(normalize=True) * 100)
```

## 3) An√°lise explorat√≥ria (gr√°ficos r√°pidos)

Esses gr√°ficos permitem visualizar como cada vari√°vel num√©rica do motor est√° distribu√≠da. Observamos que algumas vari√°veis, como Engine rpm, apresentam uma distribui√ß√£o mais concentrada, enquanto outras, como press√µes e temperaturas, t√™m distribui√ß√µes multimodais, sugerindo que existem diferentes condi√ß√µes de opera√ß√£o ou registros an√¥malos. Essa an√°lise √© importante porque ajuda a identificar padr√µes, poss√≠veis outliers e diferen√ßas de comportamento entre regimes de funcionamento do motor, o que pode impactar na detec√ß√£o de falhas ou na previs√£o da condi√ß√£o do motor.

A matriz de correla√ß√£o mostra que, no conjunto de dados, a maior parte das vari√°veis n√£o apresenta rela√ß√£o linear significativa entre si. A √∫nica correla√ß√£o mais percept√≠vel √© entre a rota√ß√£o do motor (Engine rpm) e a condi√ß√£o do motor (Engine Condition), que aparece como uma correla√ß√£o negativa fraca (-0,27). Isso sugere que, conforme a rota√ß√£o aumenta, a condi√ß√£o do motor pode tender a se deteriorar levemente, enquanto as demais vari√°veis analisadas se comportam de forma praticamente independente.

```python
num_cols = df.select_dtypes(include=['int64','float64']).columns.tolist()
if 'Engine Condition' in num_cols:
    num_cols.remove('Engine Condition')

plt.figure(figsize=(14,8))
for i, col in enumerate(num_cols, 1):
    plt.subplot(2,3,i)
    sns.histplot(df[col], kde=True)
    plt.title(col)
plt.tight_layout()
plt.show()

plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Matriz de correla√ß√£o')
plt.show()
```

## 4) Prepara√ß√£o dos dados e split
O dataset foi dividido em dois subconjuntos: 80% dos dados (15.628 registros) foram reservados para treinar o modelo e 20% (3.907 registros) para test√°-lo. Essa separa√ß√£o garante que o modelo seja avaliado em dados que ele nunca viu, permitindo verificar sua capacidade de generaliza√ß√£o. Al√©m disso, o uso de estratifica√ß√£o assegura que a distribui√ß√£o das classes da vari√°vel alvo seja mantida tanto no treino quanto no teste.

```python
print('Duplicados:', df.duplicated().sum())
df = df.drop_duplicates()

X = df.drop('Engine Condition', axis=1)
y = df['Engine Condition']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
)
print('Tamanho treino:', X_train.shape, ' | teste:', X_test.shape)
print('Distribui√ß√£o treino:', y_train.value_counts(normalize=True))
print('Distribui√ß√£o teste:', y_test.value_counts(normalize=True))
```

## 5) Baseline (DummyClassifier)
O modelo baseline alcan√ßou 63% de acur√°cia simplesmente por prever sempre a classe mais frequente (classe 1). No entanto, ele falhou totalmente em identificar a classe 0, resultando em precis√£o, recall e f1-score iguais a 0 para essa categoria. Isso mostra que, apesar da acur√°cia parecer razo√°vel, o modelo n√£o √© √∫til para distinguir as classes. Assim, o baseline serve apenas como refer√™ncia inicial para compararmos modelos mais sofisticados, que precisam superar esse desempenho trivial.

```python
baseline = DummyClassifier(strategy='most_frequent', random_state=RANDOM_STATE)
baseline.fit(X_train, y_train)
y_pred_base = baseline.predict(X_test)
print('\n--- Baseline ---')
print('Acur√°cia:', accuracy_score(y_test, y_pred_base))
print(classification_report(y_test, y_pred_base))
```

## 6) Modelos iniciais: Regress√£o Log√≠stica e Random Forest
Foi treinado um modelo de Regress√£o Log√≠stica, que √© um algoritmo de classifica√ß√£o linear. O pipeline aplicou uma padroniza√ß√£o das vari√°veis antes do treino e, em seguida, o modelo foi avaliado no conjunto de teste. Ele alcan√ßou 64,6% de acur√°cia, superando o baseline de 63%, o que indica que conseguiu extrair alguma informa√ß√£o √∫til dos dados. No entanto, como o ganho foi pequeno, isso sugere a necessidade de testar algoritmos mais robustos (como Random Forest ou XGBoost) e aplicar t√©cnicas para lidar com o desbalanceamento de classes, a fim de melhorar a capacidade preditiva do modelo.

O modelo de Random Forest alcan√ßou 64,4% de acur√°cia, um resultado muito pr√≥ximo ao da Regress√£o Log√≠stica (64,6%) e apenas ligeiramente superior ao baseline (63%). Isso mostra que, at√© o momento, os modelos testados n√£o est√£o conseguindo separar bem as classes, possivelmente devido ao desbalanceamento ou √† falta de vari√°veis mais discriminativas. Assim, seria interessante explorar t√©cnicas de balanceamento de classes, ajustes de hiperpar√¢metros e a inclus√£o de algoritmos adicionais para tentar melhorar a performance preditiva.

```python
# Regress√£o Log√≠stica
pipe_log = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(random_state=42, max_iter=1000))
])
pipe_log.fit(X_train, y_train)
y_pred_log = pipe_log.predict(X_test)
print('\n--- Logistic Regression ---')
print(classification_report(y_test, y_pred_log))

# Random Forest
pipe_rf = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=-1))
])
pipe_rf.fit(X_train, y_train)
y_pred_rf = pipe_rf.predict(X_test)
print('\n--- Random Forest ---')
print(classification_report(y_test, y_pred_rf))

# Import√¢ncia das vari√°veis
importances = pipe_rf.named_steps['clf'].feature_importances_
feat_importance = pd.Series(importances, index=X.columns).sort_values(ascending=False)
plt.figure(figsize=(8,4))
sns.barplot(x=feat_importance.values, y=feat_importance.index)
plt.title('Import√¢ncia das vari√°veis - Random Forest')
plt.show()
```

## 7) Otimiza√ß√£o (GridSearch) para Random Forest
O Random Forest otimizado conseguiu uma boa taxa de acerto para os motores bons (classe 1), mas teve dificuldade em identificar corretamente os motores ruins (classe 0). Isso aconteceu porque os dados est√£o desbalanceados (muito mais exemplos de motores bons do que ruins), e o modelo tende a ‚Äúaprender‚Äù mais sobre a classe majorit√°ria.

```python
param_grid = {
    'clf__n_estimators': [50, 100],
    'clf__max_depth': [None, 10, 20],
    'clf__min_samples_split': [2, 5]
}
cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=RANDOM_STATE)
grid = GridSearchCV(pipe_rf, param_grid, cv=cv, scoring='f1', n_jobs=-1)
grid.fit(X_train, y_train)
print('\nMelhores par√¢metros:', grid.best_params_)
best_model = grid.best_estimator_
y_pred_best = best_model.predict(X_test)
print('\n--- Random Forest Otimizado ---')
print(classification_report(y_test, y_pred_best))

# Matriz de confus√£o
cm = confusion_matrix(y_test, y_pred_best)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confus√£o - Melhor Modelo')
plt.show()
```

## 8) Balanceamento e modelos avan√ßados (SMOTE + XGBoost/LightGBM)
O log do LightGBM mostra que, ap√≥s aplicarmos o SMOTE, as classes ficaram balanceadas (aprox. 50% bons e 50% ruins). O modelo ent√£o inicia o treinamento de forma justa entre as classes e escolhe automaticamente a melhor forma de paralelizar os c√°lculos para acelerar o processo. Isso confirma que o balanceamento foi aplicado corretamente e que o algoritmo est√° rodando como esperado.

```python
from imblearn.over_sampling import SMOTE
from imblearn.pipeline import Pipeline as ImbPipeline
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

# Random Forest + SMOTE
pipe_rf_bal = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('scaler', StandardScaler()),
    ('clf', RandomForestClassifier(random_state=42, n_jobs=-1))
])
pipe_rf_bal.fit(X_train, y_train)

# XGBoost + SMOTE
pipe_xgb = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('scaler', StandardScaler()),
    ('clf', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))
])
pipe_xgb.fit(X_train, y_train)

# LightGBM + SMOTE
pipe_lgbm = ImbPipeline([
    ('smote', SMOTE(random_state=42)),
    ('scaler', StandardScaler()),
    ('clf', LGBMClassifier(random_state=42))
])
pipe_lgbm.fit(X_train, y_train)
```

## 9) Compara√ß√£o entre modelos com valida√ß√£o cruzada
A compara√ß√£o mostrou que a Regress√£o Log√≠stica foi o modelo mais eficiente, superando inclusive t√©cnicas mais complexas como Random Forest, XGBoost e LightGBM com SMOTE. O melhor F1 m√©dio foi 0.759, enquanto o pior foi 0.669, uma diferen√ßa significativa. Isso indica que os algoritmos mais avan√ßados n√£o conseguiram superar o modelo simples e que ainda existe espa√ßo para melhorar, seja ajustando melhor os hiperpar√¢metros, testando outras formas de balanceamento ou explorando mais vari√°veis.

```python
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)

modelos = {
    'Logistic Regression': pipe_log,
    'Random Forest (GridSearch)': best_model,
    'Random Forest + SMOTE': pipe_rf_bal,
    'XGBoost + SMOTE': pipe_xgb,
    'LightGBM + SMOTE': pipe_lgbm
}
resultados = {}
for nome, modelo in modelos.items():
    scores = cross_val_score(modelo, X, y, cv=cv, scoring='f1')
    resultados[nome] = [scores.mean(), scores.std()]

resultados_df = pd.DataFrame(resultados, index=['F1 m√©dio', 'Desvio Padr√£o']).T
print('\n===== Compara√ß√£o entre modelos =====')
print(resultados_df)

plt.figure(figsize=(8,5))
sns.barplot(x=resultados_df.index, y=resultados_df['F1 m√©dio'])
plt.xticks(rotation=30)
plt.ylabel('F1 m√©dio (valida√ß√£o cruzada)')
plt.title('Compara√ß√£o de Modelos')
plt.show()

melhor = resultados_df['F1 m√©dio'].max()
pior = resultados_df['F1 m√©dio'].min()
print('\nResumo final:')
print(f"Melhor modelo teve F1 m√©dio de {melhor:.3f}")
print(f"Pior modelo teve F1 m√©dio de {pior:.3f}")
if melhor - pior < 0.05:
    print("üëâ Todos os modelos ficaram muito pr√≥ximos ‚Üí limite est√° nos dados.")
else:
    print("üëâ Houve diferen√ßa significativa entre os modelos ‚Üí ainda h√° espa√ßo para melhorar.")
```

O modelo otimizado apresenta um desempenho muito bom nos dados de treino (77,6%), mas seu desempenho cai para 65,6% nos dados de teste. A diferen√ßa de aproximadamente 12 pontos indica que o modelo pode estar sofrendo overfitting, ou seja, est√° ajustado demais aos dados de treino e n√£o generaliza t√£o bem para dados novos. Para melhorar, podemos considerar t√©cnicas como regulariza√ß√£o, poda do modelo, coleta de mais dados ou valida√ß√£o cruzada para reduzir o overfitting.

## 10) Salvar modelo final

```python
joblib.dump(best_model, 'best_model_engine.pkl')
print('\n‚úÖ Modelo salvo: best_model_engine.pkl')
```

